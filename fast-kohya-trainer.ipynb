{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/fast-kohya-trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=linaqruf.fast-kohya-trainer) [![](https://dcbadge.vercel.app/api/shield/931591564424253512?style=flat)](https://lookup.guru/931591564424253512) [![ko-fi](https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat)](https://ko-fi.com/linaqruf) <a href=\"https://saweria.co/linaqruf\"><img alt=\"Saweria\" src=\"https://img.shields.io/badge/Saweria-7B3F00?style=flat&logo=ko-fi&logoColor=white\"/></a>\n",
        "# **Fast Kohya Trainer** <small>(Lazy Edition)</small><br><small><small>The same [Kohya Trainer](https://github.com/Linaqruf/kohya-trainer) except it's faster and 1-click cell üöÄ \n"
      ],
      "metadata": {
        "id": "BHxO7OWcixGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHANGES**:<br>\n",
        "- (11/02):<br>\n",
        "‚ùì Fix `broken path` problem, like `/content/drive/` to `/content/drive/MyDrive/`<br>\n",
        "‚ùì Deleted advanced args like `lr_scheduler_num_cycles`, `lr_scheduler_power`, and `network_train_on`. You can specify it in `additional arguments` field instead.<br>\n",
        "‚úÖ Now support downloading compressed dataset (`.zip`) and automatically extract it to `train_data_dir`<br>\n",
        "‚úÖ It's `2-in-1` feature so you can download-and-extract zipfile from `url` or only extract zipfile from mounted gdrive `path`<br>\n"
      ],
      "metadata": {
        "id": "wtC0KA-dtdN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**FEATURES**:<br>\n",
        "‚úÖ 1-click cell üöÄ<br>\n",
        "‚úÖ Support both `LoRA` and `Native Training`<br>\n",
        "‚úÖ Load dataset from üìù `Google Drive` <br>\n",
        "‚úÖ xformers precompiled wheels available up to üê≥ `A100`<br>\n",
        "‚úÖ Support input custom tag <br>\n",
        "‚úÖ Faster download for pretrained model and vae using `aria2c 16 threading` üöÄ<br>\n",
        "‚ùå Not Flexible <br>\n",
        "‚ùå Dreambooth method not included because of how hard registering `train_data_dir` with `<repeats>_<token> <class>`<br>\n",
        "‚ùå Currently registering diffusers model for pretrained model is not supported<br>\n",
        "‚ùå Don't expect much from this version because most of important features are filtered out\n"
      ],
      "metadata": {
        "id": "blOl7pljN-J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NVxpMKh_FcbY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TN0aDXTsiwW9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## Start Your Engine üöÄ\n",
        "import os\n",
        "import time\n",
        "import textwrap\n",
        "import yaml\n",
        "import shutil\n",
        "from subprocess import getoutput\n",
        "from google.colab import drive\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# List\n",
        "installVae = []\n",
        "\n",
        "# huggingface token for download\n",
        "user_token = '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'\n",
        "user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  \n",
        "#@markdown ##<br> General Config\n",
        "#@markdown <small><font color=gray> **HINT**: `LoRA` or `Native Training`? you can specify it here. </small><br>\n",
        "mode = \"LoRA\" #@param [\"LoRA\", \"native-training\"]\n",
        "output_to_drive = False #@param {'type':'boolean'}\n",
        "install_xformers = True #@param {'type':'boolean'}\n",
        "\n",
        "# Define Variable\n",
        "root_dir = \"/content\"\n",
        "repo_dir = f\"{root_dir}/kohya-trainer\"\n",
        "tools_dir = f\"{root_dir}/kohya-trainer/tools\"\n",
        "finetune_dir = f\"{root_dir}/kohya-trainer/finetune\"\n",
        "training_dir =  f\"{root_dir}/training_dir\"\n",
        "pretrained_model = f\"{root_dir}/pretrained_model\"\n",
        "vae = f\"{root_dir}/vae\"\n",
        "\n",
        "if output_to_drive:\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    drive.mount('/content/drive')\n",
        "  training_dir = \"/content/drive/MyDrive/training_dir\"\n",
        "\n",
        "# Accelerate Config\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "project_name = \"neurosama\" #@param {'type' : 'string'}\n",
        "train_data_dir = \"/content/training_dir/train_data\" #@param {'type' : 'string'}\n",
        "#@markdown <small><font color=gray> **HINT**: specify this part if your dataset are in `zip` and uploaded somewhere, this will download your dataset and automatically extract them to `train_data_dir` </small><br> \n",
        "dataset_zip_url = \"\" #@param {'type': 'string'}\n",
        "zipfile = \"train_data.zip\"\n",
        "\n",
        "meta_clean = f\"{training_dir}/meta_clean.json\"\n",
        "meta_cap_dd = f\"{training_dir}/meta_cap_dd.json\"\n",
        "meta_cap = f\"{training_dir}/meta_cap.json\"\n",
        "meta_lat = f\"{training_dir}/meta_lat.json\"\n",
        "output_dir = f\"{training_dir}/output\"\n",
        "\n",
        "# V2 Inference\n",
        "inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "\n",
        "# For Dataset Cleaning\n",
        "supported_types = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\", \".caption\", \".npz\", \".txt\", \".json\"]\n",
        "\n",
        "# Make Directory\n",
        "os.chdir(root_dir)\n",
        "if not os.path.exists(repo_dir):\n",
        " !git clone \"https://github.com/Linaqruf/kohya-trainer\" {repo_dir}\n",
        "\n",
        "os.makedirs(repo_dir, exist_ok=True)\n",
        "os.makedirs(tools_dir, exist_ok=True)\n",
        "os.makedirs(finetune_dir, exist_ok=True)\n",
        "os.makedirs(training_dir, exist_ok=True)\n",
        "os.makedirs(pretrained_model, exist_ok=True)\n",
        "os.makedirs(vae, exist_ok=True)\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "\n",
        "def install_dependencies():\n",
        "  !pip -q install --upgrade gdown\n",
        "  !apt -q install liblz4-tool aria2\n",
        "  !pip -q install --upgrade -r requirements.txt\n",
        "\n",
        "  s = getoutput('nvidia-smi')\n",
        "  if install_xformers:\n",
        "    if 'T4' in s:\n",
        "      %pip -q install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.16/xformers-0.0.16+814314d.d20230118-cp38-cp38-linux_x86_64.whl\n",
        "      !pip -q install --pre triton\n",
        "    if 'A100' in s:\n",
        "      %pip -q install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15+e163309.d20230103.ColabProA100-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "  if not os.path.exists(accelerate_config):\n",
        "    from accelerate.utils import write_basic_config\n",
        "    write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "  !export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "install_dependencies()\n",
        "\n",
        "#@markdown ##<br> Download Pretrained Model\n",
        "modelUrl = \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\" #@param {'type': 'string'}\n",
        "#@markdown <small><font color=gray> **HINT**: useful for downloading pretrained model outside huggingface</small><br>\n",
        "modelName = \"anything-v3-1.safetensors\" #@param {'type': 'string'}\n",
        "if not modelName:\n",
        "  modelName = os.path.basename(modelUrl)\n",
        "modelPath = f\"{pretrained_model}/{modelName}\"\n",
        "\n",
        "#@markdown ##<br> Download VAE (Optional)\n",
        "vaeUrl = [\"\", \\\n",
        "          \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/vae/animevae.pt\", \\\n",
        "          \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt\", \\\n",
        "          \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"]\n",
        "vaeList = [\"none\", \\\n",
        "           \"anime.vae.pt\", \\\n",
        "           \"waifudiffusion.vae.pt\", \\\n",
        "           \"stablediffusion.vae.pt\"]\n",
        "vaeName = \"anime.vae.pt\" #@param [\"none\", \"anime.vae.pt\", \"waifudiffusion.vae.pt\", \"stablediffusion.vae.pt\"]\n",
        "vaePath = f\"{vae}/{vaeName}\"\n",
        "\n",
        "installVae.append((vaeName, vaeUrl[vaeList.index(vaeName)]))\n",
        "\n",
        "def install_model(url, name, is_vae):\n",
        "  ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "  if not is_vae:\n",
        "    if url.startswith(\"https://drive.google.com\"):\n",
        "      os.chdir(pretrained_model)\n",
        "      !gdown --fuzzy {url}\n",
        "    elif url.startswith(\"https://huggingface.co/\"):\n",
        "      if '/blob/' in url:\n",
        "        url = url.replace('/blob/', '/resolve/')\n",
        "      !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {pretrained_model} -o {name} {url}\n",
        "    else:\n",
        "      !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {pretrained_model} -o {name} {url}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -o vae/{name} \"{url}\"\n",
        "\n",
        "os.chdir(root_dir)\n",
        "install_model(modelUrl, modelName, False)\n",
        "if vaeName != \"none\":\n",
        "  for vae in installVae:\n",
        "      install_model(vae[1], vae[0], True)\n",
        "\n",
        "# Unzip Dataset if any\n",
        "def download_dataset(url):\n",
        "  if url.startswith(\"/content\"):\n",
        "    !unzip -j -o {url} -d \"{train_data_dir}\"\n",
        "  elif url.startswith(\"https://drive.google.com\"):\n",
        "    os.chdir(root_dir)\n",
        "    !gdown --fuzzy  {url}\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir} -o {zipfile} {url}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {root_dir} -o {zipfile} {url}\n",
        "\n",
        "if dataset_zip_url:\n",
        "  download_dataset(dataset_zip_url)\n",
        "\n",
        "  !unzip -j -o \"{root_dir}/{zipfile}\" -d \"{train_data_dir}\"\n",
        "  os.remove(f\"{root_dir}/{zipfile}\")\n",
        "\n",
        "  files_to_move = (\"meta_cap.json\", \\\n",
        "                    \"meta_cap_dd.json\", \\\n",
        "                    \"meta_lat.json\", \\\n",
        "                    \"meta_clean.json\")\n",
        "\n",
        "  for filename in os.listdir(train_data_dir):\n",
        "    file_path = os.path.join(train_data_dir, filename)\n",
        "    if filename in files_to_move:\n",
        "      if not os.path.exists(file_path):\n",
        "        shutil.move(file_path, training_dir)\n",
        "      else: \n",
        "        os.remove(file_path)\n",
        "\n",
        "# Clean Dataset\n",
        "for item in os.listdir(train_data_dir):\n",
        "  file_ext = os.path.splitext(item)[1]\n",
        "  if file_ext not in supported_types:\n",
        "    print(f\"Deleting unsupported file {item} from {train_data_dir}\")\n",
        "    os.remove(os.path.join(train_data_dir, item))\n",
        "\n",
        "#@markdown ##<br> Auto-captioning\n",
        "#@markdown <small><font color=gray> **HINT**: this part will be skipped if you have `any` `.caption` or `.txt` inside your `train_data_dir` </small><br> \n",
        "use_wd_tagger = True #@param{type:\"boolean\"}\n",
        "use_blip = False #@param{type:\"boolean\"}\n",
        "\n",
        "#@markdown ##<br> Custom Tag\n",
        "extension = \"txt\" #@param [\"txt\", \"caption\"]\n",
        "custom_tag = \"\" #@param {type:\"string\"}\n",
        "#@markdown Tick this if you want to append custom tag at the end of lines instead\n",
        "append = False #@param {type:\"boolean\"}\n",
        "keep_tokens = 1 #@param {type:\"number\"}\n",
        "\n",
        "def add_tag(filename, tag, append):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "        \t    \t\n",
        "    tag = \", \".join(tag.split())\n",
        "    tag = tag.replace(\"_\", \" \")\n",
        "    \n",
        "    if tag in contents:\n",
        "        return\n",
        "        \n",
        "    if not keep_tokens:\n",
        "      contents = contents.rstrip() + \", \" + tag if append else tag + \", \" + contents\n",
        "    else:\n",
        "      contents = tag + \", \" + contents\n",
        "    \n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "tags = custom_tag.split()\n",
        "for filename in os.listdir(train_data_dir):\n",
        "    if filename.endswith(\".\" + extension):\n",
        "        for tag in tags:\n",
        "            add_tag(os.path.join(train_data_dir, filename), tag, append)\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "if use_wd_tagger:\n",
        "  if not any(file.endswith('.txt') for file in os.listdir(train_data_dir)):\n",
        "    !python tag_images_by_wd14_tagger.py \\\n",
        "      \"{train_data_dir}\" \\\n",
        "      --batch_size 8 \\\n",
        "      --repo_id \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\" \\\n",
        "      --thresh 0.35 \\\n",
        "      --caption_extension .txt \\\n",
        "      --max_data_loader_n_workers 2\n",
        "if use_blip:\n",
        "  if not any(file.endswith('.caption') for file in os.listdir(train_data_dir)):\n",
        "    !python make_captions.py \\\n",
        "      \"{train_data_dir}\" \\\n",
        "      --batch_size 8 \\\n",
        "      --beam_search \\\n",
        "      --caption_extension .caption \\\n",
        "      --max_data_loader_n_workers 2\n",
        "\n",
        "# Create JSON file for Finetuning\n",
        "if os.path.exists(train_data_dir):\n",
        "  if any(file.endswith('.caption') for file in os.listdir(train_data_dir)):\n",
        "    !python merge_captions_to_metadata.py \\\n",
        "      {train_data_dir} \\\n",
        "      {meta_cap}\n",
        "\n",
        "  if any(file.endswith('.txt') for file in os.listdir(train_data_dir)):\n",
        "    !python merge_dd_tags_to_metadata.py \\\n",
        "      {train_data_dir} \\\n",
        "      {meta_cap_dd}\n",
        "else:\n",
        "  print(\"train_data_dir does not exist or is not a directory.\")\n",
        "\n",
        "if os.path.exists(meta_cap):\n",
        "  !python merge_dd_tags_to_metadata.py \\\n",
        "    {train_data_dir} \\\n",
        "    --in_json {meta_cap} \\\n",
        "    {meta_cap_dd}\n",
        "\n",
        "if os.path.exists(meta_cap_dd):\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {meta_cap_dd} \\\n",
        "    {meta_clean}\n",
        "elif os.path.exists(meta_cap):\n",
        "  !python clean_captions_and_tags.py \\\n",
        "    {meta_cap} \\\n",
        "    {meta_clean}\n",
        "\n",
        "#@markdown ##<br> LoRA Config\n",
        "\n",
        "network_dim = 128 #@param {'type':'number'}\n",
        "network_alpha = 128 #@param {'type':'number'}\n",
        "\n",
        "#@markdown `network_weights` can be specified to resume training.\n",
        "network_weights = \"\" #@param {'type':'string'}\n",
        "unet_lr = 1e-4 #@param {'type':'number'}\n",
        "text_encoder_lr = 5e-5 #@param {'type':'number'}\n",
        "if not os.path.exists(network_weights):\n",
        "  network_weights =\"\"\n",
        "\n",
        "#@markdown ##<br> Training Config\n",
        "#@markdown <small><font color=gray> **HINT**: specify `v2` if you train on SDv2 base Model, with `v2_parameterization` for SDv2 768 Model</small><br>  \n",
        "v2 = False #@param{type:\"boolean\"}\n",
        "v_parameterization = False #@param {type:\"boolean\"}\n",
        "resolution = \"512\" #@param [\"512\", \"640\", \"768\"] {allow-input: false}\n",
        "flip_aug = False #@param{type:\"boolean\"}\n",
        "skip_existing_latents = True #@param{type:\"boolean\"}\n",
        "#@markdown <small><font color=gray> **HINT**: try lowering `train_batch_size` if you do native training, around 4 batch sizes\n",
        "train_batch_size = 6 #@param {type:\"number\"}\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  if mode == \"native-training\" and train_batch_size > 4:\n",
        "    train_batch_size = 4\n",
        "  elif mode == \"LoRA\" and train_batch_size > 8:\n",
        "    train_batch_size = 8\n",
        "\n",
        "max_train_type = \"max_train_epochs\" #@param [\"max_train_steps\", \"max_train_epochs\"]\n",
        "max_train_type_value = 20 #@param {type:\"number\"}\n",
        "dataset_repeats = 10 #@param {type:\"number\"}\n",
        "#@markdown <small><font color=gray> **HINT**: for LoRA if you specify both `--unet_lr` and `--text_encoder_lr` you don't need this, however it's still recorded to metadata</small><br>  \n",
        "learning_rate = 2e-6 #@param {type:\"number\"}\n",
        "lr_scheduler = \"constant\" #@param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"] {allow-input: false}\n",
        "mixed_precision = \"fp16\" #@param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_n_epochs_type = \"save_n_epoch_ratio\" #@param [\"save_every_n_epochs\", \"save_n_epoch_ratio\"] {allow-input: false}\n",
        "save_n_epochs_type_value = 3 #@param {type:\"number\"}\n",
        "save_model_as = \"safetensors\" #@param [\"ckpt\", \"pt\", \"safetensors\"] {allow-input: false}\n",
        "clip_skip = 2 #@param {type:\"number\"}\n",
        "logging_dir = \"/content/training_dir/logs\"\n",
        "additional_argument = \"--shuffle_caption --xformers\" #@param {type:\"string\"}\n",
        "print_hyperparameter = True\n",
        "\n",
        "# V2 Config\n",
        "if v2 and not v_parameterization:\n",
        "  inference_url += \"v2-inference.yaml\"\n",
        "if v2 and v_parameterization:\n",
        "  inference_url += \"v2-inference-v.yaml\"\n",
        "\n",
        "# Download config\n",
        "if v2:\n",
        "  !wget {inference_url} -O {output_dir}/{project_name}.yaml \n",
        "\n",
        "# Max Resolution\n",
        "if resolution == \"512\":\n",
        "  max_resolution = \"512,512\"\n",
        "elif resolution == \"640\":\n",
        "  max_resolution = \"640,640\"\n",
        "else:\n",
        "  max_resolution = \"768,768\"\n",
        "\n",
        "# Run script to prepare buckets and latent\n",
        "\n",
        "bucket_latents=f\"\"\"\n",
        "python prepare_buckets_latents.py \\\n",
        "  {train_data_dir} \\\n",
        "  {meta_clean} \\\n",
        "  {meta_lat} \\\n",
        "  {modelPath} \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--flip_aug\" if flip_aug else \"\"} \\\n",
        "  {\"--skip_existing\" if skip_existing_latents else \"\"} \\\n",
        "  {\"--min_bucket_reso \" + format(320) if resolution != \"512\" else \"--min_bucket_reso \" + format(256)} \\\n",
        "  {\"--max_bucket_reso \" + format(1280) if resolution != \"512\" else \"--max_bucket_reso \" + format(1024)} \\\n",
        "  {\"--batch_size \" + format(8)} \\\n",
        "  {\"--max_resolution \" + format(max_resolution)} \\\n",
        "  --mixed_precision no\n",
        "  \"\"\"\n",
        "  \n",
        "f = open(\"./bucket_latents.sh\", \"w\")\n",
        "f.write(bucket_latents)\n",
        "f.close()\n",
        "!chmod +x ./bucket_latents.sh\n",
        "!./bucket_latents.sh\n",
        "\n",
        "# Start Training\n",
        "os.chdir(repo_dir)\n",
        "train_command=f\"\"\"\n",
        "accelerate launch --config_file={accelerate_config} --num_cpu_threads_per_process=8 {f\"{repo_dir}/train_network.py\" if mode == \"LoRA\" else f\"{repo_dir}/fine_tune.py\"} \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  {\"--network_dim=\" + format(network_dim) if mode == \"LoRA\" else \"\"} \\\n",
        "  {\"--network_alpha=\" + format(network_alpha) if mode == \"LoRA\" else \"\"} \\\n",
        "  {\"--network_module=networks.lora\" if mode == \"LoRA\" else \"\"} \\\n",
        "  {(\"--network_weights=\" + network_weights if network_weights else \"\") if mode == \"LoRA\" else \"\"} \\\n",
        "  --learning_rate={learning_rate} \\\n",
        "  {(\"--unet_lr=\" + format(unet_lr) if unet_lr else \"\") if mode == \"LoRA\" else \"\"} \\\n",
        "  {(\"--text_encoder_lr=\" + format(text_encoder_lr) if text_encoder_lr else \"\") if mode == \"LoRA\" else \"\"}  \\\n",
        "  --lr_scheduler={lr_scheduler} \\\n",
        "  --pretrained_model_name_or_path={modelPath} \\\n",
        "  {\"--vae=\" + vaePath if vaePath else \"\"} \\\n",
        "  --train_data_dir={train_data_dir} \\\n",
        "  --in_json={meta_lat} \\\n",
        "  --output_dir={output_dir} \\\n",
        "  {\"--keep_tokens=\" + format(keep_tokens) if custom_tag else \"\"} \\\n",
        "  {\"--output_name=\" + project_name if project_name else \"\"} \\\n",
        "  --mixed_precision={mixed_precision} \\\n",
        "  --save_precision={save_precision} \\\n",
        "  {\"--save_every_n_epochs=\" + format(save_n_epochs_type_value) if save_n_epochs_type==\"save_every_n_epochs\" else \"\"} \\\n",
        "  {\"--save_n_epoch_ratio=\" + format(save_n_epochs_type_value) if save_n_epochs_type==\"save_n_epoch_ratio\" else \"\"} \\\n",
        "  --save_model_as={save_model_as} \\\n",
        "  --resolution={resolution} \\\n",
        "  --train_batch_size={train_batch_size} \\\n",
        "  {\"--max_token_length=\" + format(225)} \\\n",
        "  --use_8bit_adam \\\n",
        "  --dataset_repeats={dataset_repeats} \\\n",
        "  {\"--max_train_epochs=\" + format(max_train_type_value) if max_train_type == \"max_train_epochs\" else \"\"} \\\n",
        "  {\"--max_train_steps=\" + format(max_train_type_value) if max_train_type == \"max_train_steps\" else \"\"} \\\n",
        "  {\"--clip_skip=\" + format(clip_skip) if v2 == False else \"\"} \\\n",
        "  --logging_dir={logging_dir} \\\n",
        "  --log_prefix={project_name} \\\n",
        "  {additional_argument}\n",
        "  \"\"\"\n",
        "\n",
        "debug_params = [\"v2\", \\\n",
        "                \"v_parameterization\", \\\n",
        "                \"network_dim\" if mode == \"LoRA\" else \"\" , \\\n",
        "                \"network_alpha\" if mode == \"LoRA\" else \"\" , \\\n",
        "                \"network_weights\" if mode == \"LoRA\" else \"\", \\\n",
        "                \"learning_rate\", \\\n",
        "                \"unet_lr\" if mode == \"LoRA\" else \"\", \\\n",
        "                \"text_encoder_lr\" if mode == \"LoRA\" else \"\", \\\n",
        "                \"lr_scheduler\", \\\n",
        "                \"modelPath\", \\\n",
        "                \"vaePath\", \\\n",
        "                \"train_data_dir\", \\\n",
        "                \"meta_lat\", \\\n",
        "                \"output_dir\", \\\n",
        "                \"keep_tokens\" if custom_tag else \"\", \\\n",
        "                \"project_name\", \\\n",
        "                \"mixed_precision\", \\\n",
        "                \"save_precision\", \\\n",
        "                \"save_n_epochs_type\", \\\n",
        "                \"save_n_epochs_type_value\", \\\n",
        "                \"save_model_as\", \\\n",
        "                \"resolution\", \\\n",
        "                \"train_batch_size\", \\\n",
        "                \"dataset_repeats\", \\\n",
        "                \"max_train_type\", \\\n",
        "                \"max_train_type_value\", \\\n",
        "                \"clip_skip\", \\\n",
        "                \"logging_dir\", \\\n",
        "                \"additional_argument\"]\n",
        "\n",
        "if print_hyperparameter:\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Hyperparameter\", \"Value\"]\n",
        "    for params in debug_params:\n",
        "        if params != \"\":\n",
        "            if globals()[params] == \"\":\n",
        "                value = \"False\"\n",
        "            else:\n",
        "                value = globals()[params]\n",
        "            table.add_row([params, value])\n",
        "    table.align = \"l\"\n",
        "    print(table)\n",
        "\n",
        "    arg_list = train_command.split()\n",
        "    mod_train_command = {'command': arg_list}\n",
        "    \n",
        "    if mode == \"LoRA\":\n",
        "      # save the YAML string to a file\n",
        "      with open(f'{training_dir}/finetune_lora_cmd.yaml', 'w') as f:\n",
        "          yaml.dump(mod_train_command, f)\n",
        "    else:\n",
        "      with open(f'{training_dir}/finetune_cmd.yaml', 'w') as f:\n",
        "            yaml.dump(mod_train_command, f)\n",
        "\n",
        "f = open(\"./train.sh\", \"w\")\n",
        "f.write(train_command)\n",
        "f.close()\n",
        "!chmod +x ./train.sh\n",
        "!./train.sh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## (Optional) EXTRAS!"
      ],
      "metadata": {
        "id": "VQrywRr9UZVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Inference: Test Your Model!\n",
        "import os\n",
        "\n",
        "#@markdown ### LoRA Config <br>\n",
        "#@markdown (leave it empty if doing native training)\n",
        "network_weight = \"\" #@param {'type':'string'}\n",
        "network_mul = 0.6 #@param {'type':'number'}\n",
        "\n",
        "#@markdown ### General Config\n",
        "v2 = False #@param {type:\"boolean\"}\n",
        "v_parameterization = False #@param {type:\"boolean\"}\n",
        "instance_prompt = \"\" #@param {type: \"string\"}\n",
        "prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\" #@param {type: \"string\"}\n",
        "negative = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type: \"string\"}\n",
        "model = \"/content/pretrained_model/anything-v3-1.safetensors\" #@param {type: \"string\"}\n",
        "vae = \"\" #@param {type: \"string\"}\n",
        "outdir = \"/content/images\" #@param {type: \"string\"}\n",
        "scale = 6 #@param {type: \"slider\", min: 1, max: 40}\n",
        "sampler = \"ddim\" #@param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "steps = 28 #@param {type: \"slider\", min: 1, max: 100}\n",
        "precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "width = 512 #@param {type: \"integer\"}\n",
        "height = 768 #@param {type: \"integer\"}\n",
        "images_per_prompt = 4 #@param {type: \"integer\"}\n",
        "batch_size = 4 #@param {type: \"integer\"}\n",
        "clip_skip = 2 #@param {type: \"slider\", min: 1, max: 40}\n",
        "seed = -1 #@param {type: \"integer\"}\n",
        "\n",
        "final_prompt = f\"{instance_prompt}, {prompt} --n {negative}\" if instance_prompt else f\"{prompt} --n {negative}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "!python gen_img_diffusers.py \\\n",
        "  {\"--v2\" if v2 else \"\"} \\\n",
        "  {\"--v_parameterization\" if v2 and v_parameterization else \"\"} \\\n",
        "  {\"--network_module=networks.lora\" if network_weight else \"\"} \\\n",
        "  {\"--network_weight=\" + network_weight if network_weight else \"\"} \\\n",
        "  {\"--network_mul=\" + format(network_mul) if network_weight else \"\"} \\\n",
        "  --ckpt={model} \\\n",
        "  --outdir={outdir} \\\n",
        "  --xformers \\\n",
        "  {\"--vae=\" + vae if vae else \"\"} \\\n",
        "  --{precision} \\\n",
        "  --W={width} \\\n",
        "  --H={height} \\\n",
        "  {\"--seed=\" + format(seed) if seed > 0 else \"\"} \\\n",
        "  --scale={scale} \\\n",
        "  --sampler={sampler} \\\n",
        "  --steps={steps} \\\n",
        "  --max_embeddings_multiples=3 \\\n",
        "  --batch_size={batch_size} \\\n",
        "  --images_per_prompt={images_per_prompt} \\\n",
        "  {\"--clip_skip=\" + format(clip_skip) if v2 == False else \"\"} \\\n",
        "  --prompt=\"{final_prompt}\"\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P5ZZ-xmPM8Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload to Huggingface hub\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "#@markdown Login to Huggingface Hub \n",
        "#@markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\" #@param {type:\"string\"}\n",
        "login(write_token, add_to_git_credential=True)\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(write_token)\n",
        "\n",
        "#@markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "\n",
        "orgs_name = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown If your model/dataset repo didn't exist, it will automatically create your repo.\n",
        "model_name = \"your-model-name\" #@param{type:\"string\"}\n",
        "dataset_name = \"your-dataset-name\" #@param{type:\"string\"}\n",
        "make_this_model_private = True #@param{type:\"boolean\"}\n",
        "\n",
        "if orgs_name == \"\":\n",
        "  model_repo = user['name']+\"/\"+model_name.strip()\n",
        "  datasets_repo = user['name']+\"/\"+dataset_name.strip()\n",
        "else:\n",
        "  model_repo = orgs_name+\"/\"+model_name.strip()\n",
        "  datasets_repo = orgs_name+\"/\"+dataset_name.strip()\n",
        "\n",
        "if model_name != \"\":\n",
        "  try:\n",
        "      validate_repo_id(model_repo)\n",
        "      api.create_repo(repo_id=model_repo, \n",
        "                      private=make_this_model_private)\n",
        "      print(\"Model Repo didn't exists, creating repo\")\n",
        "      print(\"Model Repo: \",model_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Model Repo: {model_repo} exists, skipping create repo\\n\")\n",
        "\n",
        "if dataset_name != \"\":\n",
        "  try:\n",
        "      validate_repo_id(datasets_repo)\n",
        "      api.create_repo(repo_id=datasets_repo,\n",
        "                      repo_type=\"dataset\",\n",
        "                      private=make_this_model_private)\n",
        "      print(\"Dataset Repo didn't exists, creating repo\")\n",
        "      print(\"Dataset Repo\",datasets_repo,\"created!\\n\")\n",
        "\n",
        "  except HfHubHTTPError as e:\n",
        "      print(f\"Dataset repo: {datasets_repo} exists, skipping create repo\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QTXsM170GUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Model\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown #### This will be uploaded to model repo\n",
        "model_path = \"/content/training_dir/output/last.safetensors\" #@param {type :\"string\"}\n",
        "path_in_repo = \"\" #@param {type :\"string\"}\n",
        "\n",
        "#@markdown #### Other Information\n",
        "commit_message = \"\" #@param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "  commit_message = \"feat: upload \"+project_name+\" lora model\"\n",
        "def upload_model(model_paths, is_folder :bool):\n",
        "  path_obj = Path(model_paths)\n",
        "  trained_model = path_obj.parts[-1]\n",
        "  \n",
        "  if path_in_repo:\n",
        "    trained_model = path_in_repo\n",
        "    \n",
        "  if is_folder == True:\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "    \n",
        "    api.upload_folder(\n",
        "        folder_path=model_paths,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\"\n",
        "        )\n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/tree/main\\n\")\n",
        "  else: \n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/\"+model_repo)\n",
        "    print(f\"Please wait...\")\n",
        "            \n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_paths,\n",
        "        path_in_repo=trained_model,\n",
        "        repo_id=model_repo,\n",
        "        commit_message=commit_message,\n",
        "        )\n",
        "        \n",
        "    print(f\"Upload success, located at https://huggingface.co/\"+model_repo+\"/blob/main/\"+trained_model+\"\\n\")\n",
        "      \n",
        "def upload():\n",
        "    if model_path.endswith((\".ckpt\", \".safetensors\", \".pt\")):\n",
        "      upload_model(model_path, False)\n",
        "    else:\n",
        "      upload_model(model_path, True)\n",
        "\n",
        "upload()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CIeoJA-eO-8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Dataset\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "#@markdown This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/training_dir/train_data\" #@param {type :\"string\"}\n",
        "meta_lat_path = \"/content/training_dir/meta_lat.json\" #@param {type :\"string\"}\n",
        "#@markdown `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/training_dir/logs\" #@param {type :\"string\"}\n",
        "\n",
        "if project_name !=\"\":\n",
        "  tmp_dataset = \"/content/training_dir/\"+project_name+\"_dataset\"\n",
        "else:\n",
        "  tmp_dataset = \"/content/training_dir/tmp_dataset\"\n",
        "\n",
        "tmp_train_data = tmp_dataset + \"/train_data\"\n",
        "dataset_zip = tmp_dataset + \".zip\"\n",
        "\n",
        "#@markdown Other Information\n",
        "commit_message = \"\" #@param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "  commit_message = \"feat: upload \"+project_name+\" dataset and logs\"\n",
        "\n",
        "os.makedirs(tmp_dataset, exist_ok=True)\n",
        "os.makedirs(tmp_train_data, exist_ok=True)\n",
        "\n",
        "def upload_dataset(dataset_paths, is_zip : bool):\n",
        "  path_obj = Path(dataset_paths)\n",
        "  dataset_name = path_obj.parts[-1]\n",
        "\n",
        "  if is_zip:\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=dataset_paths,\n",
        "        path_in_repo=dataset_name,\n",
        "        repo_id=datasets_repo,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message,\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/blob/main/\"+dataset_name+\"\\n\")\n",
        "  else:\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/\"+datasets_repo)\n",
        "    print(f\"Please wait...\")\n",
        "\n",
        "    api.upload_folder(\n",
        "        folder_path=dataset_paths,\n",
        "        path_in_repo=dataset_name,\n",
        "        repo_id=datasets_repo,\n",
        "        repo_type=\"dataset\",\n",
        "        commit_message=commit_message,\n",
        "        ignore_patterns=\".ipynb_checkpoints\",\n",
        "    )\n",
        "    print(f\"Upload success, located at https://huggingface.co/datasets/\"+datasets_repo+\"/tree/main/\"+dataset_name+\"\\n\")\n",
        "  \n",
        "def zip_file(tmp):\n",
        "    zipfiles = tmp + \".zip\" \n",
        "    with zipfile.ZipFile(zipfiles, 'w') as zip:\n",
        "      for tmp, dirs, files in os.walk(tmp):\n",
        "          for file in files:\n",
        "              zip.write(os.path.join(tmp, file))\n",
        "\n",
        "def move(src_path, dst_path, is_metadata: bool):\n",
        "  files_to_move = [\"meta_cap.json\", \\\n",
        "                   \"meta_cap_dd.json\", \\\n",
        "                   \"meta_lat.json\", \\\n",
        "                   \"meta_clean.json\", \\\n",
        "                   \"meta_final.json\"]\n",
        "\n",
        "  if os.path.exists(src_path):\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "  if is_metadata:\n",
        "    parent_meta_path = os.path.dirname(src_path)\n",
        "\n",
        "    for filename in os.listdir(parent_meta_path):\n",
        "      file_path = os.path.join(parent_meta_path, filename)\n",
        "      if filename in files_to_move:\n",
        "        shutil.move(file_path, dst_path)\n",
        "\n",
        "def upload():\n",
        "  if train_data_path !=\"\" and meta_lat_path !=\"\":\n",
        "    move(train_data_path, tmp_train_data, False)\n",
        "    move(meta_lat_path, tmp_dataset, True)\n",
        "    zip_file(tmp_dataset)\n",
        "    upload_dataset(dataset_zip, True)\n",
        "  if logs_path !=\"\":\n",
        "    upload_dataset(logs_path, False)\n",
        "\n",
        "upload()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IW-hS9jnmf-E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}