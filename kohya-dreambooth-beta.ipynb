{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-dreambooth-beta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kohya Dreambooth - VRAM 12GB"
      ],
      "metadata": {
        "id": "slgjeYgd6pWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted to Google Colab based on [Kohya Guide](https://note.com/kohya_ss/n/nbf7ce8d80f29#c9d7ee61-5779-4436-b4e6-9053741c46bb)<br>\n",
        "Adapted again from [bmaltais's Kohya Archive](https://github.com/bmaltais/kohya_ss)<br>\n",
        "Adapted to Google Colab by [Linaqruf](https://github.com/Linaqruf)<br>\n",
        "Inference cell adapted from [ShivamShrirao's Dreambooth](https://colab.research.google.com/github/ShivamShrirao/diffusers/blob/main/examples/dreambooth/DreamBooth_Stable_Diffusion.ipynb)<br>\n",
        "You can find latest notebook update [here](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer-v3-stable.ipynb)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPgBR3KM6E-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install Kohya Trainer"
      ],
      "metadata": {
        "id": "tTVqCAgSmie4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Clone Kohya Trainer\n",
        "%cd /content/\n",
        "!git clone https://github.com/Linaqruf/kohya-trainer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Dependencies\n",
        "%cd /content/kohya-trainer\n",
        "\n",
        "#install python 3.9\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "#3.9.6\n",
        "!sudo apt-get install python3.9-distutils && wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py\n",
        "\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install -r requirements.txt\n",
        "!pip install -U gallery-dl\n",
        "!pip install tensorflow\n",
        "\n",
        "#install xformers\n",
        "!pip install -U -I --no-deps https://github.com/AbdBarho/stable-diffusion-webui-docker/releases/download/2.1.0/xformers-0.0.14.dev0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set config for `!Accelerate`\n",
        "#@markdown #Hint\n",
        "\n",
        "#@markdown 1. **In which compute environment are you running?** ([0] This machine, [1] AWS (Amazon SageMaker)): `0`\n",
        "#@markdown 2. **Which type of machine are you using?** ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU [4] MPS): `0`\n",
        "#@markdown 3. **Do you want to run your training on CPU only (even if a GPU is available)?** [yes/NO]: `NO`\n",
        "#@markdown 4. **Do you want to use DeepSpeed?** [yes/NO]: `NO`\n",
        "#@markdown 5. **What GPU(s) (by id) should be used for training on this machine as a comma-seperated list?** [all] = `all`\n",
        "#@markdown 6. **Do you wish to use FP16 or BF16 (mixed precision)?** [NO/fp16/bf16]: `fp16`\n",
        "%cd /content/kohya-trainer\n",
        "!accelerate config"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnjHb4wgD7vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folders configuration\n",
        "\n",
        "Refer to the note to understand how to create the folde structure. In short it should look like:\n",
        "\n",
        "```\n",
        "<arbitrary folder name>\n",
        "|- <arbitrary class folder name>\n",
        "    |- <repeat count>_<class>\n",
        "|- <arbitrary training folder name>\n",
        "   |- <repeat count>_<token> <class>\n",
        "```\n",
        "\n",
        "Example for `asd dog` where `asd` is the token word and `dog` is the class. In this example the regularization `dog` class images contained in the folder will be repeated only 1 time and the `asd dog` images will be repeated 20 times:\n",
        "\n",
        "```\n",
        "my_asd_dog_dreambooth\n",
        "|- reg_dog\n",
        "    |- 1_dog\n",
        "       `- reg_image_1.png\n",
        "       `- reg_image_2.png\n",
        "       ...\n",
        "       `- reg_image_256.png\n",
        "|- train_dog\n",
        "    |- 20_asd dog\n",
        "       `- dog1.png\n",
        "       ...\n",
        "       `- dog8.png\n",
        "```"
      ],
      "metadata": {
        "id": "En9UUwGNMRMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.isdir('/content/dreambooth'):\n",
        "  pass\n",
        "else:\n",
        "  !mkdir /content/dreambooth\n",
        "\n",
        "#@title Create train and reg folder\n",
        "#@markdown #Create reg folder\n",
        "reg_count = 1 #@param {type: \"integer\"}\n",
        "reg_class =\"hitokomoru\" #@param {type: \"string\"}\n",
        "reg_folder = str(reg_count) + \"_\" + reg_class\n",
        "\n",
        "#@markdown #Create train folder\n",
        "train_count = 2 #@param {type: \"integer\"}\n",
        "train_token = \"sls\" #@param {type: \"string\"}\n",
        "train_class = \"hitokomoru\" #@param {type: \"string\"}\n",
        "train_folder = str(train_count) + \"_\" + train_token + \" \" + train_class\n",
        "\n",
        "!mkdir \"/content/dreambooth/reg_{reg_class}\"\n",
        "!mkdir \"/content/dreambooth/reg_{reg_class}/{reg_folder}\"\n",
        "!mkdir \"/content/dreambooth/train_{train_class}\"\n",
        "!mkdir \"/content/dreambooth/train_{train_class}/{train_folder}\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-CVfXAJMSqRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Datasets"
      ],
      "metadata": {
        "id": "Pz9A2bu1Cq73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare Regularization Images\n",
        "#@markdown Download regularization images provided by community\n",
        "category = \"husbando-regularization-3.5k\" #@param [\"\", \"waifu-regularization-3.3k\", \"husbando-regularization-3.5k\"]\n",
        "#@markdown Or you can use the file manager on the left panel to upload (drag and drop) to `reg_images` folder (it uploads faster)\n",
        "def reg_images(url, name):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} \"{url}\" -O /content/dreambooth/reg_{reg_class}/{reg_folder}/{name}.zip\n",
        "\n",
        "if category != \"\":\n",
        "  if category == \"waifu-regularization-3.3k\":\n",
        "    reg_images(\"https://huggingface.co/datasets/waifu-research-department/regularization/resolve/main/waifu-regularization-3.3k.zip\", \"waifu-regularization-3.3k\")\n",
        "    !unzip /content/dreambooth/reg_{reg_class}/{reg_folder}/waifu-regularization-3.3k.zip -d /content/dreambooth/reg_{reg_class}/{reg_folder}\n",
        "    !rm /content/dreambooth/reg_{reg_class}/{reg_folder}/waifu-regularization-3.3k.zip\n",
        "  else:\n",
        "    reg_images(\"https://huggingface.co/datasets/waifu-research-department/regularization/resolve/main/husbando-regularization-3.5k.zip\", \"husbando-regularization-3.5k\")\n",
        "    !unzip /content/dreambooth/reg_{reg_class}/{reg_folder}/husbando-regularization-3.5k.zip -d  /content/dreambooth/reg_{reg_class}/{reg_folder}\n",
        "    !rm /content/dreambooth/reg_{reg_class}/{reg_folder}/husbando-regularization-3.5k.zip\n",
        " \n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R9JZSOuSzXe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare Train Images\n",
        "#@markdown **How this work?**\n",
        "\n",
        "#@markdown By using **gallery-dl** we can scrap or bulk download images on Internet, on this notebook we will scrap images from Danbooru using tag1 and tag2 as target scraping.\n",
        "#@title Booru Scraper\n",
        "%cd /content\n",
        "\n",
        "tag = \"hito_komoru\" #@param {type: \"string\"}\n",
        "tag2 = \"\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "booru = \"Gelbooru\" #@param [\"\", \"Danbooru\", \"Gelbooru\"]\n",
        "\n",
        "if tag2 is not \"\":\n",
        "  tag = tag + \"+\" + tag2\n",
        "else:\n",
        "  tag = tag\n",
        "\n",
        "output_dir = \"/content/dreambooth/train_\"+ train_class +\"/\"+ train_folder\n",
        "\n",
        "if booru == \"Danbooru\":\n",
        "  !gallery-dl \"https://danbooru.donmai.us/posts?tags={tag}\" -D \"{output_dir}\"\n",
        "elif booru == \"Gelbooru\":\n",
        "  !gallery-dl \"https://gelbooru.com/index.php?page=post&s=list&tags={tag}\" -D \"{output_dir}\"\n",
        "else:\n",
        "  pass\n",
        "\n",
        "#@markdown Or you can use the file manager on the left panel to upload (drag and drop) to `train_images` folder. \n",
        "\n",
        "#@markdown The output directory will be on `/content/dreambooth/reg_{reg_class}/{reg_folder}`. We also will use this folder as target folder for training next step.\n",
        "\n"
      ],
      "metadata": {
        "id": "Kt1GzntK_apb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#`(NEW)` Waifu Diffusion 1.4 Autotagger"
      ],
      "metadata": {
        "id": "SoPUJaTpTusz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Weight\n",
        "%cd /content/kohya-trainer/\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def huggingface_dl(url, weight):\n",
        "  user_token = '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'\n",
        "  user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  !wget -c --header={user_header} {url} -O /content/kohya-trainer/wd14tagger-weight/{weight}\n",
        "\n",
        "def download_weight():\n",
        "  !mkdir /content/kohya-trainer/wd14tagger-weight/\n",
        "  huggingface_dl(\"https://huggingface.co/Linaqruf/personal_backup/resolve/main/wd14tagger-weight/wd14Tagger.zip\", \"wd14Tagger.zip\")\n",
        "  \n",
        "  !unzip /content/kohya-trainer/wd14tagger-weight/wd14Tagger.zip -d /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "  # Destination path \n",
        "  destination = '/content/kohya-trainer/wd14tagger-weight'\n",
        "\n",
        "  if os.path.isfile('/content/kohya-trainer/tag_images_by_wd14_tagger.py'):\n",
        "    # Move the content of \n",
        "    # source to destination \n",
        "    shutil.move(\"tag_images_by_wd14_tagger.py\", destination) \n",
        "  else:\n",
        "    pass\n",
        "\n",
        "download_weight()"
      ],
      "metadata": {
        "id": "WDSlAEHzT2Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Autotagger\n",
        "%cd /content/kohya-trainer/wd14tagger-weight\n",
        "\n",
        "output_dir = \"/content/dreambooth/train_\"+ train_class +\"/\"+ train_folder\n",
        "\n",
        "!python tag_images_by_wd14_tagger.py --batch_size 4 {output_dir}\n",
        "\n",
        "#@markdown Args list:\n",
        "#@markdown - `--train_data_dir` : directory for training images\n",
        "#@markdown - `--model` : model path to load\n",
        "#@markdown - `--tag_csv` : csv file for tag\n",
        "#@markdown - `--thresh` : threshold of confidence to add a tag\n",
        "#@markdown - `--batch_size` : batch size in inference\n",
        "#@markdown - `--model` : model path to load\n",
        "#@markdown - `--caption_extension` : extension of caption file\n",
        "#@markdown - `--debug` : debug mode\n"
      ],
      "metadata": {
        "id": "hibZK5NPTjZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Pre-trained Model \n",
        "%cd /content/kohya-trainer\n",
        "!mkdir checkpoint\n",
        "\n",
        "#@title Install Pre-trained Model \n",
        "\n",
        "installModels=[]\n",
        "\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available pretrained model to download:\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/model-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal_backup/resolve/main/animeckpt/modelsfw-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp16.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned-fp32.ckpt\", \\\n",
        "            \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt\" \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \\\n",
        "            \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Animesfw-final-pruned\", \\\n",
        "             \"Anything-V3.0-pruned-fp16\", \\\n",
        "             \"Anything-V3.0-pruned-fp32\", \\\n",
        "             \"Anything-V3.0-pruned\", \\\n",
        "             \"Stable-Diffusion-v1-4\", \\\n",
        "             \"Stable-Diffusion-v1-5-pruned-emaonly\" \\\n",
        "             \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "modelName = \"Anything-V3.0-pruned-fp32\" #@param [\"\", \"Animefull-final-pruned\", \"Animesfw-final-pruned\", \"Anything-V3.0-pruned-fp16\", \"Anything-V3.0-pruned-fp32\", \"Anything-V3.0-pruned\", \"Stable-Diffusion-v1-4\", \"Stable-Diffusion-v1-5-pruned-emaonly\", \"Waifu-Diffusion-v1-3-fp32\"]\n",
        "\n",
        "#@markdown ### Custom model\n",
        "#@markdown The model URL should be a direct download link.\n",
        "customName = \"\" #@param {'type': 'string'}\n",
        "customUrl = \"\"#@param {'type': 'string'}\n",
        "\n",
        "if customName == \"\" or customUrl == \"\":\n",
        "  pass\n",
        "else:\n",
        "  installModels.append((customName, customUrl))\n",
        "\n",
        "if modelName != \"\":\n",
        "  # Map model to URL\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy -O \"/content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\" \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt \"{url}\"\n",
        "  else:\n",
        "    user_token = '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'\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    !wget -c --header={user_header} \"{url}\" -O /content/kohya-trainer/checkpoint/{checkpoint_name}.ckpt\n",
        "\n",
        "def install_checkpoint():\n",
        "  for model in installModels:\n",
        "    install(model[0], model[1])\n",
        "install_checkpoint()\n",
        "\n"
      ],
      "metadata": {
        "id": "SoucgZQ6jgPQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Training\n",
        "\n"
      ],
      "metadata": {
        "id": "yHNbl3O_NSS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training begin\n",
        "num_cpu_threads_per_process = 8 #@param {'type':'integer'}\n",
        "pre_trained_model_path =\"Linaqruf/anything-v3.0\" #@param {'type':'string'}\n",
        "train_data_dir = \"/content/dreambooth/train_hitokomoru\" #@param {'type':'string'}\n",
        "reg_data_dir = \"/content/dreambooth/reg_hitokomoru\" #@param {'type':'string'}\n",
        "output_dir =\"/content/dreambooth\" #@param {'type':'string'}\n",
        "train_batch_size = 1  #@param {type: \"slider\", min: 1, max: 10}\n",
        "resolution = \"512,512\" #@param [\"512,512\", \"768,768\"] {allow-input: false}\n",
        "learning_rate =\"2e-6\" #@param {'type':'string'}\n",
        "mixed_precision = \"fp16\" #@param [\"fp16\", \"bf16\"] {allow-input: false}\n",
        "max_train_steps = 5000 #@param {'type':'integer'}\n",
        "save_precision = \"fp16\" #@param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs = 10 #@param {'type':'integer'}\n",
        "\n",
        "%cd /content/kohya-trainer\n",
        "!accelerate launch --num_cpu_threads_per_process {num_cpu_threads_per_process} train_db_fixed_v11.py \\\n",
        "    --pretrained_model_name_or_path={pre_trained_model_path} \\\n",
        "    --train_data_dir={train_data_dir} \\\n",
        "    --reg_data_dir={reg_data_dir} \\\n",
        "    --output_dir={output_dir} \\\n",
        "    --prior_loss_weight=1.0 \\\n",
        "    --resolution={resolution} \\\n",
        "    --train_batch_size={train_batch_size}\\\n",
        "    --learning_rate={learning_rate}\\\n",
        "    --max_train_steps={max_train_steps}  \\\n",
        "    --use_8bit_adam \\\n",
        "    --xformers \\\n",
        "    --mixed_precision={mixed_precision} \\\n",
        "    --enable_bucket \\\n",
        "    --cache_latents \\\n",
        "    --gradient_checkpointing \\\n",
        "    --save_every_n_epochs={save_every_n_epochs}"
      ],
      "metadata": {
        "id": "X_Rd3Eh07xlA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert trained model to ckpt\n",
        "\n",
        "#@markdown This cell will convert output weight to checkpoint file so it can be used in Web UI like Auto1111's\n",
        "WEIGHTS_DIR = \"/content/dreambooth/last\" #@param {'type':'string'}\n",
        "#@markdown Run conversion.\n",
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "\n",
        "half_arg = \"\"\n",
        "#@markdown  Whether to convert to fp16, takes half the space (2GB).\n",
        "fp16 = True #@param {type: \"boolean\"}\n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rM5o1gUu97yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR             # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None\n",
        "\n",
        "#@markdown Can set random seed here for reproducibility.\n",
        "g_cuda = torch.Generator(device='cuda')\n",
        "seed = 123123 #@param {type:\"number\"}\n",
        "g_cuda.manual_seed(seed)\n",
        "\n",
        "#@title Run for generating images.\n",
        "\n",
        "prompt = \"hatsune miku\" #@param {type:\"string\"}\n",
        "negative_prompt = \"\" #@param {type:\"string\"}\n",
        "num_samples = 1 #@param {type:\"number\"}\n",
        "guidance_scale = 7.5 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cKn2ARpLAI0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Miscellaneous"
      ],
      "metadata": {
        "id": "vqfgyL-thgdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount to Google Drive\n",
        "mount_drive= False #@param {'type':'boolean'}\n",
        "\n",
        "if mount_drive== True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OuRqOSp2eU6t",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Huggingface_hub Integration"
      ],
      "metadata": {
        "id": "QtVP2le8PL2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Instruction:\n",
        "0. Of course you need a Huggingface Account first\n",
        "1. Create huggingface token, go to `Profile > Access Tokens > New Token > Create a new access token` with the `Write` role.\n",
        "2. All cells below are checked `opt-out` by default so you need to uncheck it if you want to running the cells."
      ],
      "metadata": {
        "id": "tbKgmh_AO5NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to HuggingFace ðŸ¤—\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in ðŸ¤— Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "# https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_At5XJWW-uXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to Huggingface hub\n",
        "#@markdown Opt-out this cell when run all\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "#@markdown Prepare your Huggingface token\n",
        "\n",
        "saved_token= \"save-your-write-token-here\" #@param {'type': 'string'}\n",
        "\n",
        "if opt_out == False:\n",
        " \n",
        "  from huggingface_hub import notebook_login\n",
        "  notebook_login()\n",
        "\n"
      ],
      "metadata": {
        "id": "Da7awoqAPJ3a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Commit trained model to Huggingface"
      ],
      "metadata": {
        "id": "jypUkLWc48R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instruction:\n",
        "0. Create huggingface repository for model\n",
        "1. Clone your model to this colab session\n",
        "2. Move these necessary file to your repository to save your trained model to huggingface\n",
        "\n",
        ">in `content/kohya-trainer/fine-tuned`\n",
        "- File `epoch-nnnnn.ckpt` and/or\n",
        "- File `last.ckpt`, \n",
        "\n",
        "4. Commit your model to huggingface"
      ],
      "metadata": {
        "id": "TvZgRSmKVSRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone Model\n",
        "\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  Repository_url = \"https://huggingface.co/Linaqruf/alphanime-diffusion\" #@param {'type': 'string'}\n",
        "  !git clone {Repository_url}\n",
        "else:\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "182Law9oUiYN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Commit to Huggingface\n",
        "#@markdown Opt-out this cell when run all\n",
        "opt_out= True #@param {'type':'boolean'}\n",
        "\n",
        "if opt_out == False:\n",
        "  %cd /content\n",
        "  #@markdown Go to your model path\n",
        "  model_path= \"alphanime-diffusion\" #@param {'type': 'string'}\n",
        "\n",
        "  #@markdown Your path look like /content/**model_path**\n",
        "  #@markdown ___\n",
        "  #@markdown #Git Commit\n",
        "\n",
        "  #@markdown Set **git commit identity**\n",
        "\n",
        "  email= \"your-email\" #@param {'type': 'string'}\n",
        "  name= \"your-name\" #@param {'type': 'string'}\n",
        "  #@markdown Set **commit message**\n",
        "  commit_m= \"this is commit message\" #@param {'type': 'string'}\n",
        "\n",
        "  %cd \"/content/{model_path}\"\n",
        "  !git lfs install\n",
        "  !huggingface-cli lfs-enable-largefiles .\n",
        "  !git add .\n",
        "  !git lfs help smudge\n",
        "  !git config --global user.email \"{email}\"\n",
        "  !git config --global user.name \"{name}\"\n",
        "  !git commit -m \"{commit_m}\"\n",
        "  !git push\n",
        "\n",
        "else:\n",
        "  pass"
      ],
      "metadata": {
        "id": "87wG7QIZbtZE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}